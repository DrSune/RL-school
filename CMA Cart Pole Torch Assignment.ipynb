{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES for CartPole Torch (assignment version)\n",
    "### Christian Igel, 2024\n",
    "\n",
    "If you have suggestions for improvement, [let me know](mailto:igel@diku.dk).\n",
    "\n",
    "You may need the following packages:\n",
    "\n",
    "``pip install gymnasium[classic-control]``\n",
    "\n",
    "``python -m pip install cma``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym  # Defines RL environments\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)  # Set size of visualization\n",
    "from IPython.display import clear_output  # For inline visualization\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cma\n",
    "\n",
    "# Define task\n",
    "env = gym.make('CartPole-v1')\n",
    "state_space_dimension = env.observation_space.shape[0]\n",
    "action_space_dimension = 1  # env.action_space.n - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32) \n",
      " Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space, '\\n', env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Define the variable and the likelihood function\n",
    "sigma2 = sp.symbols('sigma2')\n",
    "sigma = sp.symbols('sigma')\n",
    "a = sp.symbols('a')\n",
    "\n",
    "likelihood = 1/sp.sqrt(2*sp.pi*sigma2) * sp.exp(-a**2/(2*sigma2))\n",
    "\n",
    "log_likelihood = -1/2 * sp.log(2 * sp.pi * sigma2) - a**2 / (2 * sigma2)\n",
    "\n",
    "\n",
    "derivative = sp.diff(likelihood, sigma2)\n",
    "\n",
    "log_derivative = sp.diff(log_likelihood, sigma2)\n",
    "\n",
    "print(derivative, '\\n', log_derivative)\n",
    "\n",
    "\n",
    "solution = sp.solve(derivative, sigma2)\n",
    "\n",
    "log_solution = sp.solve(log_derivative, sigma2)\n",
    "\n",
    "\n",
    "print(solution,log_solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the policy network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=5, output_size=1, use_bias=True):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.hidden = nn.Linear(4, 5, bias=use_bias)  # 4 input features -> 5 hidden neurons\n",
    "        self.output = nn.Linear(5, 1, bias=use_bias)  # 5 hidden neurons -> 1 output neuron\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass of the network. \"\"\"\n",
    "        x = torch.tanh(self.hidden(x))  # Apply tanh activation to hidden layer\n",
    "        x = self.output(x)  # Linear activation at output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "model = PolicyNet(input_size=input_size, use_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 31\n"
     ]
    }
   ],
   "source": [
    "d = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "print(\"Number of parameters:\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_policy(policy_net):\n",
    "    env_render = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "    state = env_render.reset()  # Forget about previous episode\n",
    "    state_tensor = torch.Tensor( state[0].reshape((1, state_space_dimension)) )\n",
    "    steps = 0\n",
    "    print(state_tensor)\n",
    "    while True:\n",
    "        out = policy_net(state_tensor)\n",
    "        a = int(out > 0)\n",
    "        state, reward, terminated, truncated, _ = env_render.step(a)  # Simulate pole\n",
    "        steps+=1\n",
    "        state_tensor = torch.Tensor( state.reshape((1, state_space_dimension)) )\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(env_render.render())\n",
    "        plt.show()\n",
    "        print(\"step:\", steps)\n",
    "        if(terminated or truncated): \n",
    "            break\n",
    "    env_render.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 15\n"
     ]
    }
   ],
   "source": [
    "visualize_policy(PolicyNet(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the objective/reward function. \n",
    "When the task is solved the functions returns -1000.\n",
    "One successful trial is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_cart_pole(x, nn, env):\n",
    "    '''\n",
    "    Returns negative accumulated reward for single pole, fully environment.\n",
    "\n",
    "    Parameters:\n",
    "        x: Parameter vector encoding the weights.\n",
    "        nn: Parameterized model.\n",
    "        env: Environment ('CartPole-v?').\n",
    "    '''\n",
    "    torch.nn.utils.vector_to_parameters(torch.Tensor(x), nn.parameters())  # Set the policy parameters\n",
    "    \n",
    "    state = env.reset()  # Forget about previous episode\n",
    "    state_tensor = torch.Tensor( state[0].reshape((1, state_space_dimension)) )\n",
    "          \n",
    "    R = 0  # Accumulated reward\n",
    "    while True:\n",
    "        out = nn(state_tensor)\n",
    "        a = int(out > 0)\n",
    "        state, reward, terminated, truncated, _ = env.step(a)  # Simulate pole\n",
    "        state_tensor = torch.Tensor( state.reshape((1, state_space_dimension)) )\n",
    "        R += reward  # Accumulate \n",
    "        if truncated:\n",
    "            return -1000  # Episode ended, final goal reached, we consider minimization\n",
    "        if terminated:\n",
    "            return -R  # Episode ended, we consider minimization\n",
    "    return -R  # Never reached  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7_w,14)-aCMA-ES (mu_w=4.3,w_1=36%) in dimension 31 (seed=605120, Wed Feb 26 19:57:29 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     14 -1.000000000000000e+01 1.0e+00 9.32e-03  9e-03  9e-03 0:00.0\n",
      "    2     28 -1.100000000000000e+01 1.1e+00 8.83e-03  9e-03  9e-03 0:00.0\n",
      "    3     42 -1.000000000000000e+01 1.1e+00 8.61e-03  8e-03  9e-03 0:00.1\n",
      "  100   1400 -1.100000000000000e+01 2.1e+00 1.10e-02  1e-02  1e-02 0:01.5\n",
      "  200   2800 -1.000000000000000e+01 2.5e+00 1.23e-02  1e-02  1e-02 0:02.9\n",
      "  300   4200 -1.100000000000000e+01 3.2e+00 1.60e-02  1e-02  2e-02 0:04.3\n",
      "  400   5600 -1.100000000000000e+01 3.6e+00 7.23e-03  6e-03  9e-03 0:05.7\n",
      "  500   7000 -1.000000000000000e+01 4.0e+00 1.34e-02  1e-02  2e-02 0:07.0\n",
      "  600   8400 -1.000000000000000e+01 4.6e+00 8.82e-03  7e-03  1e-02 0:08.6\n",
      "  700   9800 -1.000000000000000e+01 5.5e+00 7.09e-03  5e-03  9e-03 0:10.1\n",
      "  800  11200 -1.000000000000000e+01 6.6e+00 1.06e-02  7e-03  1e-02 0:11.6\n",
      "  900  12600 -1.000000000000000e+01 7.7e+00 7.48e-03  5e-03  1e-02 0:13.0\n",
      " 1000  14000 -1.000000000000000e+01 9.3e+00 9.78e-03  7e-03  1e-02 0:14.4\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      " 1100  15400 -1.100000000000000e+01 1.1e+01 4.58e-03  3e-03  7e-03 0:15.8\n",
      " 1200  16800 -1.000000000000000e+01 1.2e+01 2.81e-03  2e-03  4e-03 0:17.2\n",
      " 1300  18200 -1.100000000000000e+01 1.4e+01 5.86e-03  4e-03  8e-03 0:18.6\n",
      " 1305  18270 -1.100000000000000e+01 1.3e+01 5.95e-03  4e-03  8e-03 0:18.7\n",
      "termination on tolstagnation=1306 (Wed Feb 26 19:57:49 2025)\n",
      "final/bestever f-value = -1.100000e+01 -1.100000e+01 after 18270/18 evaluations\n",
      "incumbent solution: [-0.11753681  0.08522438  0.34314273  0.12303173 -0.31199663 -0.24966178\n",
      "  0.01493619 -0.17569118 ...]\n",
      "std deviations: [0.00432797 0.00618181 0.00718335 0.00498889 0.00687857 0.00658078\n",
      " 0.00642872 0.0062505  ...]\n",
      "best solution found after 18 evaluations\n"
     ]
    }
   ],
   "source": [
    "# Generate initial search point and initial hidden RNN states\n",
    "initial_weights = np.random.normal(0, 0.01, d)  # Random parameters for initial policy, d denotes the number of weights\n",
    "initial_sigma = .01 # Initial global step-size sigma\n",
    "\n",
    "# Do the optimization\n",
    "res = cma.fmin(fitness_cart_pole,  # Objective function\n",
    "               initial_weights,  # Initial search point\n",
    "               initial_sigma,  # Initial global step-size sigma\n",
    "               args=([PolicyNet(4), env]),  # Arguments passed to the fitness function\n",
    "               options={'ftarget': -999.9, 'tolflatfitness':1000, 'eval_final_mean':False})\n",
    "env.close()\n",
    "\n",
    "# Set the policy parameters to the final solution\n",
    "torch.nn.utils.vector_to_parameters(torch.Tensor(res[0]), model.parameters())  \n",
    "\n",
    "print(\"best solution found after\", res[2], \"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7_w,14)-aCMA-ES (mu_w=4.3,w_1=36%) in dimension 31 (seed=745287, Wed Feb 26 19:57:49 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     14 -1.090000000000000e+02 1.0e+00 9.36e-03  9e-03  9e-03 0:00.0\n",
      "    2     28 -8.600000000000000e+01 1.1e+00 9.17e-03  9e-03  9e-03 0:00.1\n",
      "    3     42 -8.800000000000000e+01 1.1e+00 9.01e-03  9e-03  9e-03 0:00.1\n",
      "    8    112 -1.000000000000000e+03 1.2e+00 8.67e-03  8e-03  9e-03 0:00.9\n",
      "termination on ftarget=-999.9 (Wed Feb 26 19:57:50 2025)\n",
      "final/bestever f-value = -1.000000e+03 -1.000000e+03 after 112/112 evaluations\n",
      "incumbent solution: [-0.0120553   0.00089924  0.00352232  0.04225083  0.01895467  0.00560596\n",
      "  0.00147084 -0.01175298 ...]\n",
      "std deviations: [0.00849091 0.00862438 0.0086129  0.0088912  0.00854775 0.00854262\n",
      " 0.00857644 0.00877245 ...]\n",
      "best solution found after 112 evaluations\n"
     ]
    }
   ],
   "source": [
    "# Generate initial search point and initial hidden RNN states\n",
    "initial_weights = np.random.normal(0, 0.01, d)  # Random parameters for initial policy, d denotes the number of weights\n",
    "initial_sigma = .01 # Initial global step-size sigma\n",
    "\n",
    "# Do the optimization\n",
    "res = cma.fmin(fitness_cart_pole,  # Objective function\n",
    "               initial_weights,  # Initial search point\n",
    "               initial_sigma,  # Initial global step-size sigma\n",
    "               args=([PolicyNet(4, use_bias=False), env]),  # Arguments passed to the fitness function\n",
    "               options={'ftarget': -999.9, 'tolflatfitness':1000, 'eval_final_mean':False})\n",
    "env.close()\n",
    "\n",
    "# Set the policy parameters to the final solution\n",
    "torch.nn.utils.vector_to_parameters(torch.Tensor(res[0]), model.parameters())  \n",
    "\n",
    "print(\"best solution found after\", res[2], \"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "import torch\n",
    "import numpy as np\n",
    "#import gym\n",
    "\n",
    "# Assuming PolicyNet, model, and fitness_cart_pole are defined elsewhere\n",
    "\n",
    "def run_experiment(use_bias, num_trials=10):\n",
    "    evaluations_list = []\n",
    "    balancing_times = []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        env = gym.make('CartPole-v1')  # Or your specific CartPole environment\n",
    "        d = sum(param.numel() for param in model.parameters())\n",
    "        initial_weights = np.random.normal(0, 0.01, d)\n",
    "        initial_sigma = 0.01\n",
    "\n",
    "        if use_bias:\n",
    "            policy_net = PolicyNet(4)\n",
    "        else:\n",
    "            policy_net = PolicyNet(4, use_bias=False)\n",
    "\n",
    "        res = cma.fmin(fitness_cart_pole, initial_weights, initial_sigma,\n",
    "                       args=([policy_net, env]),\n",
    "                       options={'ftarget': -999.9, 'tolflatfitness': 1000, 'eval_final_mean': False})\n",
    "\n",
    "        evaluations_list.append(res[2])  # Store the number of evaluations\n",
    "\n",
    "        # Load the trained weights into the policy network\n",
    "        torch.nn.utils.vector_to_parameters(torch.Tensor(res[0]), policy_net.parameters())\n",
    "\n",
    "        # Evaluate the trained network from random starting positions\n",
    "        #total_balancing_time = 0\n",
    "        #for _ in range(5):  # Run a few evaluation episodes\n",
    "        #    obs = env.reset()\n",
    "        #    done = False\n",
    "        #    balancing_time = 0\n",
    "        #    while not done:\n",
    "        #        # Extract the observation array from the tuple\n",
    "        #        observation_array = obs[0]\n",
    "        #        \n",
    "        #        action = policy_net(torch.FloatTensor(observation_array)).argmax().item()\n",
    "        #        \n",
    "        #        # Update obs with the new tuple from env.step()\n",
    "        #        obs = env.step(action)\n",
    "                \n",
    "        #        balancing_time += 1\n",
    "        #    total_balancing_time += balancing_time\n",
    "        #balancing_times.append(total_balancing_time / 5)  # Average balancing time\n",
    "\n",
    "        env.close()\n",
    "\n",
    "        # Print update after each trial\n",
    "        print(f\"Trial {trial + 1}/{num_trials} (Bias: {use_bias}) completed.\")\n",
    "\n",
    "    return evaluations_list, balancing_times\n",
    "\n",
    "# Run experiments\n",
    "evaluations_with_bias, balancing_times_with_bias = run_experiment(use_bias=True)\n",
    "evaluations_without_bias, balancing_times_without_bias = run_experiment(use_bias=False)\n",
    "\n",
    "# Analyze the results\n",
    "print(\"\\nWith Bias:\")\n",
    "print(\"Average Evaluations:\", np.mean(evaluations_with_bias))\n",
    "print(\"Average Balancing Time:\", np.mean(balancing_times_with_bias))\n",
    "\n",
    "print(\"\\nWithout Bias:\")\n",
    "print(\"Average Evaluations:\", np.mean(evaluations_without_bias))\n",
    "print(\"Average Balancing Time:\", np.mean(balancing_times_without_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=606630, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.4\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:26 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/1 evaluations\n",
      "incumbent solution: [ 0.02135461 -0.04169109 -0.01208957  0.04916689 -0.07585813  0.05754246\n",
      "  0.00748579 -0.00896958 ...]\n",
      "std deviations: [0.0991581  0.0991584  0.09915785 0.09915851 0.09915849 0.09915895\n",
      " 0.09915798 0.09915848 ...]\n",
      "Trial 1/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=688709, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 9.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:26 2025)\n",
      "final/bestever f-value = 9.000000e+00 9.000000e+00 after 24/1 evaluations\n",
      "incumbent solution: [ 0.01953138  0.03124117  0.0382144  -0.01176626 -0.03767442  0.00990766\n",
      " -0.03679298  0.06791705 ...]\n",
      "std deviations: [0.09915867 0.09915867 0.09915856 0.09915863 0.09915823 0.09915845\n",
      " 0.09915924 0.0991586  ...]\n",
      "Trial 2/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=696195, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:26 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/3 evaluations\n",
      "incumbent solution: [ 3.72282106e-03 -1.65860868e-02 -4.81698787e-02  4.45060973e-02\n",
      "  5.49555001e-02  5.50932999e-05 -1.11113532e-02  4.56214939e-02 ...]\n",
      "std deviations: [0.09916014 0.09916065 0.09916039 0.09916052 0.09916009 0.09916111\n",
      " 0.09916008 0.09916064 ...]\n",
      "Trial 3/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=714831, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 9.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:26 2025)\n",
      "final/bestever f-value = 9.000000e+00 9.000000e+00 after 24/1 evaluations\n",
      "incumbent solution: [ 0.04840033 -0.00192081  0.04109896  0.00789233 -0.00874906  0.02769519\n",
      "  0.00032186  0.03113199 ...]\n",
      "std deviations: [0.09915233 0.09915329 0.09915254 0.09915319 0.09915309 0.09915246\n",
      " 0.0991531  0.09915221 ...]\n",
      "Trial 4/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=763710, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:26 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/9 evaluations\n",
      "incumbent solution: [-0.00133365  0.01849574  0.01476529 -0.04547447  0.02215042 -0.0293291\n",
      " -0.04240352  0.05552509 ...]\n",
      "std deviations: [0.09915701 0.09915714 0.09915668 0.09915729 0.09915776 0.09915711\n",
      " 0.09915715 0.09915805 ...]\n",
      "Trial 5/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=690542, Wed Feb 26 20:10:26 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/6 evaluations\n",
      "incumbent solution: [-0.06137416 -0.03575568  0.03065696  0.00481026 -0.08045902  0.03643372\n",
      " -0.03558311  0.03389525 ...]\n",
      "std deviations: [0.09915743 0.09915751 0.0991578  0.0991577  0.09915756 0.0991574\n",
      " 0.09915674 0.0991578  ...]\n",
      "Trial 6/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=642823, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/3 evaluations\n",
      "incumbent solution: [-0.01319006  0.01174084 -0.00901386 -0.03656809  0.03287696  0.03067215\n",
      "  0.03502216  0.05614367 ...]\n",
      "std deviations: [0.09915902 0.09915884 0.0991588  0.09915872 0.09915891 0.09915921\n",
      " 0.09915917 0.09915916 ...]\n",
      "Trial 7/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=648541, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/4 evaluations\n",
      "incumbent solution: [ 0.04527885  0.01704855 -0.00897582 -0.00120295  0.00347331 -0.02468478\n",
      "  0.02175205 -0.07660315 ...]\n",
      "std deviations: [0.09915325 0.09915266 0.09915307 0.09915321 0.09915382 0.09915293\n",
      " 0.09915347 0.09915411 ...]\n",
      "Trial 8/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=657220, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/3 evaluations\n",
      "incumbent solution: [ 0.05289543 -0.07902931 -0.06585981  0.01543646  0.03546113 -0.01979402\n",
      "  0.02362763  0.0507805  ...]\n",
      "std deviations: [0.0991577  0.0991588  0.09915815 0.09915847 0.09915806 0.09915768\n",
      " 0.09915865 0.09915845 ...]\n",
      "Trial 9/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=717161, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/7 evaluations\n",
      "incumbent solution: [ 0.00483816  0.00566838  0.01977244 -0.01038725  0.01921842  0.04306243\n",
      " -0.05489487  0.0283993  ...]\n",
      "std deviations: [0.09916002 0.09915959 0.09915907 0.09915918 0.09915944 0.09915938\n",
      " 0.09915978 0.09915947 ...]\n",
      "Trial 10/10 (Bias: True) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=731551, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 9.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.2\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 9.000000e+00 9.000000e+00 after 24/1 evaluations\n",
      "incumbent solution: [-0.06719219  0.02747705 -0.01108887  0.03673444  0.07402384 -0.00601085\n",
      " -0.0072371  -0.03370384 ...]\n",
      "std deviations: [0.09915651 0.09915743 0.09915647 0.09915632 0.09915716 0.0991566\n",
      " 0.09915718 0.09915678 ...]\n",
      "Trial 1/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=699368, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:27 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/12 evaluations\n",
      "incumbent solution: [ 0.07006178  0.06342569  0.05060314 -0.01162546  0.00104131 -0.03690711\n",
      "  0.04079336 -0.00787502 ...]\n",
      "std deviations: [0.09915635 0.09915502 0.0991542  0.09915429 0.0991538  0.09915417\n",
      " 0.09915428 0.09915532 ...]\n",
      "Trial 2/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=770073, Wed Feb 26 20:10:27 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/16 evaluations\n",
      "incumbent solution: [-0.0119143   0.0128434   0.02539652 -0.05353916 -0.02383318  0.00620325\n",
      " -0.03714871  0.05403923 ...]\n",
      "std deviations: [0.09916021 0.09916077 0.09916184 0.09916103 0.09916177 0.09916104\n",
      " 0.09916133 0.09916075 ...]\n",
      "Trial 3/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=682817, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/12 evaluations\n",
      "incumbent solution: [-0.03565066  0.04170872  0.06833197 -0.0531151   0.03525975  0.05106825\n",
      "  0.0646941  -0.09927735 ...]\n",
      "std deviations: [0.09915342 0.0991523  0.09915365 0.09915406 0.09915281 0.09915345\n",
      " 0.09915447 0.09915405 ...]\n",
      "Trial 4/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=684458, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/11 evaluations\n",
      "incumbent solution: [ 0.05309442 -0.00320339 -0.0244      0.01401962 -0.10295117  0.02761574\n",
      " -0.0138314   0.01636608 ...]\n",
      "std deviations: [0.09916046 0.09916016 0.0991605  0.09916025 0.09916074 0.09916024\n",
      " 0.09916004 0.09915963 ...]\n",
      "Trial 5/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=693635, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/2 evaluations\n",
      "incumbent solution: [-0.03873985 -0.02168462  0.0496477  -0.02523524  0.0070301   0.01171484\n",
      "  0.0302646   0.05290445 ...]\n",
      "std deviations: [0.09915332 0.09915323 0.09915421 0.09915442 0.09915353 0.09915382\n",
      " 0.09915354 0.09915418 ...]\n",
      "Trial 6/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=741604, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/4 evaluations\n",
      "incumbent solution: [ 0.01548461  0.03719449  0.04352616 -0.0224567  -0.0262755   0.00890083\n",
      " -0.02912509  0.00693214 ...]\n",
      "std deviations: [0.09916203 0.09916083 0.09916111 0.0991614  0.09916172 0.09916093\n",
      " 0.09916115 0.09916192 ...]\n",
      "Trial 7/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=682865, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.2\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/3 evaluations\n",
      "incumbent solution: [ 0.02915068 -0.02127857 -0.05908036  0.03382736 -0.08483588 -0.00209449\n",
      "  0.02512221 -0.01417368 ...]\n",
      "std deviations: [0.09916012 0.09916046 0.09915961 0.0991583  0.09916005 0.09915979\n",
      " 0.09915992 0.09916014 ...]\n",
      "Trial 8/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=762721, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.1\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:28 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/7 evaluations\n",
      "incumbent solution: [ 0.0224798   0.00789566 -0.04772143  0.0330291  -0.0292219   0.00200673\n",
      "  0.01781935  0.00498605 ...]\n",
      "std deviations: [0.09915432 0.099155   0.0991551  0.09915504 0.09915514 0.09915451\n",
      " 0.09915478 0.09915455 ...]\n",
      "Trial 9/10 (Bias: False) completed.\n",
      "(12_w,24)-aCMA-ES (mu_w=7.0,w_1=24%) in dimension 898 (seed=722299, Wed Feb 26 20:10:28 2025)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     24 8.000000000000000e+00 1.0e+00 9.92e-02  1e-01  1e-01 0:00.2\n",
      "termination on ftarget=500 (Wed Feb 26 20:10:29 2025)\n",
      "final/bestever f-value = 8.000000e+00 8.000000e+00 after 24/10 evaluations\n",
      "incumbent solution: [ 0.01811714 -0.03465202 -0.04272956 -0.01267457 -0.01574248  0.02926701\n",
      "  0.01493918 -0.05403966 ...]\n",
      "std deviations: [0.09915371 0.09915402 0.09915369 0.0991542  0.09915263 0.09915386\n",
      " 0.0991532  0.09915435 ...]\n",
      "Trial 10/10 (Bias: False) completed.\n",
      "\n",
      "With Bias:\n",
      "Average Evaluations: 3.8\n",
      "Average Balancing Time (Random Starts): 11.7\n",
      "\n",
      "Without Bias:\n",
      "Average Evaluations: 7.8\n",
      "Average Balancing Time (Random Starts): 55.160000000000004\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your PyTorch model and PolicyNet is defined\n",
    "\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, output_size=2, use_bias=True):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size, bias=use_bias)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size, bias=use_bias)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "def fitness_cart_pole(weights, policy_net, env):\n",
    "    torch.nn.utils.vector_to_parameters(torch.Tensor(weights), policy_net.parameters())\n",
    "    obs = env.reset()[0]\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = policy_net(torch.FloatTensor(obs)).argmax().item()\n",
    "        obs, _, done, _, _ = env.step(action)\n",
    "        steps += 1\n",
    "        if steps >= 500:\n",
    "            return 500\n",
    "    return steps\n",
    "\n",
    "def run_experiment(use_bias, num_trials=10):\n",
    "    evaluations_list = []\n",
    "    balancing_times = []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        env = gym.make('CartPole-v1')\n",
    "        d = sum(param.numel() for param in model.parameters())\n",
    "        initial_weights = np.random.normal(0, 0.01, d)\n",
    "        initial_sigma = 0.1 # Increased sigma for faster convergence\n",
    "\n",
    "        if use_bias:\n",
    "            policy_net = PolicyNet(4)\n",
    "        else:\n",
    "            policy_net = PolicyNet(4, use_bias=False)\n",
    "\n",
    "        res = cma.fmin(fitness_cart_pole, initial_weights, initial_sigma,\n",
    "                       args=([policy_net, env]),\n",
    "                       options={'ftarget': 500, 'tolflatfitness': 1000, 'eval_final_mean': False, 'maxiter': 5000})\n",
    "\n",
    "        evaluations_list.append(res[2])\n",
    "\n",
    "        torch.nn.utils.vector_to_parameters(torch.Tensor(res[0]), model.parameters())\n",
    "\n",
    "        total_balancing_time = 0\n",
    "        for _ in range(5):\n",
    "            obs = env.reset()[0]\n",
    "            done = False\n",
    "            balancing_time = 0\n",
    "            while not done:\n",
    "                action = policy_net(torch.FloatTensor(obs)).argmax().item()\n",
    "                obs, _, done, _, _ = env.step(action)\n",
    "                balancing_time += 1\n",
    "            total_balancing_time += balancing_time\n",
    "        balancing_times.append(total_balancing_time / 5)\n",
    "\n",
    "        env.close()\n",
    "        print(f\"Trial {trial + 1}/{num_trials} (Bias: {use_bias}) completed.\")\n",
    "\n",
    "    return evaluations_list, balancing_times\n",
    "\n",
    "# Initialize your model\n",
    "model = PolicyNet(4) # Example initialization\n",
    "\n",
    "# Run experiments\n",
    "evaluations_with_bias, balancing_times_with_bias = run_experiment(use_bias=True)\n",
    "evaluations_without_bias, balancing_times_without_bias = run_experiment(use_bias=False)\n",
    "\n",
    "# Analyze the results\n",
    "print(\"\\nWith Bias:\")\n",
    "print(\"Average Evaluations:\", np.mean(evaluations_with_bias))\n",
    "print(\"Average Balancing Time (Random Starts):\", np.mean(balancing_times_with_bias))\n",
    "\n",
    "print(\"\\nWithout Bias:\")\n",
    "print(\"Average Evaluations:\", np.mean(evaluations_without_bias))\n",
    "print(\"Average Balancing Time (Random Starts):\", np.mean(balancing_times_without_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_policy(PolicyNet(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about CMA-ES optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization \n",
    "#cma.plot();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn even more on CMA-ES\n",
    "#cma.CMAOptions() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
